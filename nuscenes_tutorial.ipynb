{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nuScenes devkit tutorial\n",
    "\n",
    "Welcome to the nuScenes tutorial. This demo assumes the database itself is available at `./data/`, and loads a mini version of the full dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Gentle Introduction to nuScenes\n",
    "\n",
    "In this part of the tutorial, let us go through a top-down introduction of our database. Our dataset comprises of elemental building blocks that are the following:\n",
    "\n",
    "1. `log` - Log information from which the data was extracted.\n",
    "2. `scene` - 20 second snippet of a car's journey.\n",
    "3. `sample` - An annotated snapshot of a scene at a particular timestamp.\n",
    "4. `sample_data` - Data collected from a particular sensor.\n",
    "5. `ego_pose` - Ego vehicle poses at a particular timestamp.\n",
    "6. `sensor` - A specific sensor type.\n",
    "7. `calibrated sensor` - Definition of a particular sensor as calibrated on a particular vehicle.\n",
    "8. `instance` - Enumeration of all object instance we observed.\n",
    "9. `category` - Taxonomy of object categories (e.g. vehicle, human). \n",
    "10. `attribute` - Property of an instance that can change while the category remains the same.\n",
    "11. `visibility` - Fraction of pixels visible in all the images collected from 6 different cameras.\n",
    "12. `sample_annotation` - An annotated instance of an object within our interest.\n",
    "13. `map` - Map data that is stored as binary semantic masks from a top-down view.\n",
    "\n",
    "The database schema is visualized below. For more information see the [nuScenes schema](https://github.com/nutonomy/nuscenes-devkit/blob/master/docs/schema_nuscenes.md) page.\n",
    "![](https://www.nuscenes.org/public/images/nuscenes-schema.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Loading NuScenes dataset for version v1.0-mini\n",
      "Loaded 23 category.\n",
      "Loaded 8 attribute.\n",
      "Loaded 4 visibility.\n",
      "Loaded 911 instance.\n",
      "Loaded 12 sensor.\n",
      "Loaded 120 calibrated_sensor.\n",
      "Loaded 31206 ego_pose.\n",
      "Loaded 8 log.\n",
      "Loaded 10 scene.\n",
      "Loaded 404 sample.\n",
      "Loaded 31206 sample_data.\n",
      "Loaded 18538 sample_annotation.\n",
      "Loaded 4 map.\n",
      "Loaded data in 592 ms\n",
      "====================\n",
      "Built reverse index in 31 ms\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('./build')\n",
    "\n",
    "from _nuscenes import NuScenes\n",
    "\n",
    "nusc = NuScenes(version='v1.0-mini', dataroot='./data/', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A look at the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. `scene`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nuScenes is a large scale database that features annotated samples across ***1000 scenes*** of approximately 20 seconds each. Let's take a look at the scenes that we have in the loaded database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Scene {\n",
       "   token: cc8c0bf57f984915a77078b10eb33198\n",
       "   nbr_samples: 39\n",
       "   first_sample_token: ca9a282c9e77460f8360f564131a8af5\n",
       "   last_sample_token: ed5fc18c31904f96a8f0dbb99ff069c0\n",
       "   name: scene-0061\n",
       " },\n",
       " Scene {\n",
       "   token: fcbccedd61424f1b85dcbf8f897f9754\n",
       "   nbr_samples: 40\n",
       "   first_sample_token: 3e8750f331d7499e9b5123e9eb70f2e2\n",
       "   last_sample_token: 281b92269fd648d4b52d06ac06ca6d65\n",
       "   name: scene-0103\n",
       " },\n",
       " Scene {\n",
       "   token: 6f83169d067343658251f72e1dd17dbc\n",
       "   nbr_samples: 41\n",
       "   first_sample_token: 8687ba92abd3406aa797115b874ebeba\n",
       "   last_sample_token: dcbe451d383e450786aaad04ab9d3790\n",
       "   name: scene-0553\n",
       " },\n",
       " Scene {\n",
       "   token: bebf5f5b2a674631ab5c88fd1aa9e87a\n",
       "   nbr_samples: 41\n",
       "   first_sample_token: 5991fad3280c4f84b331536c32001a04\n",
       "   last_sample_token: 35833ae5808e4ef186d1fdebac3d9cf6\n",
       "   name: scene-0655\n",
       " },\n",
       " Scene {\n",
       "   token: 2fc3753772e241f2ab2cd16a784cc680\n",
       "   nbr_samples: 41\n",
       "   first_sample_token: cd9964f8c3d34383b16e9c2997de1ed0\n",
       "   last_sample_token: 8fe9664cec514a58b1184c4fcefda6b5\n",
       "   name: scene-0757\n",
       " },\n",
       " Scene {\n",
       "   token: c5224b9b454b4ded9b5d2d2634bbda8a\n",
       "   nbr_samples: 40\n",
       "   first_sample_token: c1676a2feac74eee8aa38ca3901787d6\n",
       "   last_sample_token: 63c24b51feb94f14bec29022dae4975d\n",
       "   name: scene-0796\n",
       " },\n",
       " Scene {\n",
       "   token: 325cef682f064c55a255f2625c533b75\n",
       "   nbr_samples: 41\n",
       "   first_sample_token: b5989651183643369174912bc5641d3b\n",
       "   last_sample_token: b4ff30109dd14c89b24789dc5713cf8c\n",
       "   name: scene-0916\n",
       " },\n",
       " Scene {\n",
       "   token: d25718445d89453381c659b9c8734939\n",
       "   nbr_samples: 41\n",
       "   first_sample_token: 5998b71b64c146769bde1d5430741381\n",
       "   last_sample_token: ee9b3f38dadd40588f43ba590c4751b9\n",
       "   name: scene-1077\n",
       " },\n",
       " Scene {\n",
       "   token: de7d80a1f5fb4c3e82ce8a4f213b450a\n",
       "   nbr_samples: 40\n",
       "   first_sample_token: e6b0b282aa174a978272dc2d0a89d560\n",
       "   last_sample_token: 4e1d1031fe9f45f981a2f598365fc645\n",
       "   name: scene-1094\n",
       " },\n",
       " Scene {\n",
       "   token: e233467e827140efa4b42d2b4c435855\n",
       "   nbr_samples: 40\n",
       "   first_sample_token: a480496a5988410fbe3d8ed6c84da996\n",
       "   last_sample_token: abf3d91d3c28407e80e3334fe89c03cb\n",
       "   name: scene-1100\n",
       " }]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nusc.scenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a scene metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Scene {\n",
       "  token: cc8c0bf57f984915a77078b10eb33198\n",
       "  nbr_samples: 39\n",
       "  first_sample_token: ca9a282c9e77460f8360f564131a8af5\n",
       "  last_sample_token: ed5fc18c31904f96a8f0dbb99ff069c0\n",
       "  name: scene-0061\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_scene = nusc.scenes[0]\n",
    "my_scene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. `sample`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In scenes, we annotate our data every half a second (2 Hz).\n",
    "\n",
    "We define `sample` as an ***annotated keyframe of a scene at a given timestamp***. A keyframe is a frame where the time-stamps of data from all the sensors should be very close to the time-stamp of the sample it points to.\n",
    "\n",
    "Now, let us look at the first annotated sample in this scene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ca9a282c9e77460f8360f564131a8af5'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_sample_token = my_scene.first_sample_token\n",
    "first_sample_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine its metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sample {\n",
       "  token: ca9a282c9e77460f8360f564131a8af5\n",
       "  timestamp: 1532402927647951\n",
       "  scene_token: cc8c0bf57f984915a77078b10eb33198\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_sample = nusc.sample(first_sample_token)\n",
    "my_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A useful method is  `list_sample()` which lists all related `sample_data` keyframes and `sample_annotation` associated with a `sample` which we will discuss in detail in the subsequent parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "print(len(my_sample.annotations))\n",
    "print(len(my_sample.datas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. `sample_data`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nuScenes dataset contains data that is collected from a full sensor suite. Hence, for each snapshot of a scene, we provide references to a family of data that is collected from these sensors. \n",
    "\n",
    "We provide a `data` key to access these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SampleData {\n",
       "   token: 37091c75b9704e0daa829ba56dfa0906\n",
       "   sample_token: ca9a282c9e77460f8360f564131a8af5\n",
       "   filename: samples/RADAR_FRONT/n015-2018-07-24-11-22-45+0800__RADAR_FRONT__1532402927664178.pcd\n",
       "   ego_pose_token: 37091c75b9704e0daa829ba56dfa0906\n",
       "   calibrated_sensor_token: f4d2a6c281f34a7eb8bb033d82321f79\n",
       " },\n",
       " SampleData {\n",
       "   token: 11946c1461d14016a322916157da3c7d\n",
       "   sample_token: ca9a282c9e77460f8360f564131a8af5\n",
       "   filename: samples/RADAR_FRONT_LEFT/n015-2018-07-24-11-22-45+0800__RADAR_FRONT_LEFT__1532402927652686.pcd\n",
       "   ego_pose_token: 11946c1461d14016a322916157da3c7d\n",
       "   calibrated_sensor_token: 2ee327ac0903407dbb42c754861c1e63\n",
       " },\n",
       " SampleData {\n",
       "   token: 491209956ee3435a9ec173dad3aaf58b\n",
       "   sample_token: ca9a282c9e77460f8360f564131a8af5\n",
       "   filename: samples/RADAR_FRONT_RIGHT/n015-2018-07-24-11-22-45+0800__RADAR_FRONT_RIGHT__1532402927639817.pcd\n",
       "   ego_pose_token: 491209956ee3435a9ec173dad3aaf58b\n",
       "   calibrated_sensor_token: 341ad78c836f4dc4bd2c61ad12285a63\n",
       " },\n",
       " SampleData {\n",
       "   token: 312aa38d0e3e4f01b3124c523e6f9776\n",
       "   sample_token: ca9a282c9e77460f8360f564131a8af5\n",
       "   filename: samples/RADAR_BACK_LEFT/n015-2018-07-24-11-22-45+0800__RADAR_BACK_LEFT__1532402927668356.pcd\n",
       "   ego_pose_token: 312aa38d0e3e4f01b3124c523e6f9776\n",
       "   calibrated_sensor_token: 794da4b758054140bd84d26b1146e46e\n",
       " },\n",
       " SampleData {\n",
       "   token: 07b30d5eb6104e79be58eadf94382bc1\n",
       "   sample_token: ca9a282c9e77460f8360f564131a8af5\n",
       "   filename: samples/RADAR_BACK_RIGHT/n015-2018-07-24-11-22-45+0800__RADAR_BACK_RIGHT__1532402927635538.pcd\n",
       "   ego_pose_token: 07b30d5eb6104e79be58eadf94382bc1\n",
       "   calibrated_sensor_token: eff1fe2c0eaa44958bf11f7398e8293b\n",
       " },\n",
       " SampleData {\n",
       "   token: 9d9bf11fb0e144c8b446d54a8a00184f\n",
       "   sample_token: ca9a282c9e77460f8360f564131a8af5\n",
       "   filename: samples/LIDAR_TOP/n015-2018-07-24-11-22-45+0800__LIDAR_TOP__1532402927647951.pcd.bin\n",
       "   ego_pose_token: 9d9bf11fb0e144c8b446d54a8a00184f\n",
       "   calibrated_sensor_token: a183049901c24361a6b0b11b8013137c\n",
       " },\n",
       " SampleData {\n",
       "   token: e3d495d4ac534d54b321f50006683844\n",
       "   sample_token: ca9a282c9e77460f8360f564131a8af5\n",
       "   filename: samples/CAM_FRONT/n015-2018-07-24-11-22-45+0800__CAM_FRONT__1532402927612460.jpg\n",
       "   ego_pose_token: e3d495d4ac534d54b321f50006683844\n",
       "   calibrated_sensor_token: 1d31c729b073425e8e0202c5c6e66ee1\n",
       " },\n",
       " SampleData {\n",
       "   token: aac7867ebf4f446395d29fbd60b63b3b\n",
       "   sample_token: ca9a282c9e77460f8360f564131a8af5\n",
       "   filename: samples/CAM_FRONT_RIGHT/n015-2018-07-24-11-22-45+0800__CAM_FRONT_RIGHT__1532402927620339.jpg\n",
       "   ego_pose_token: aac7867ebf4f446395d29fbd60b63b3b\n",
       "   calibrated_sensor_token: f8d0aaa1a8234ba3aeed5867e0aa81aa\n",
       " },\n",
       " SampleData {\n",
       "   token: 79dbb4460a6b40f49f9c150cb118247e\n",
       "   sample_token: ca9a282c9e77460f8360f564131a8af5\n",
       "   filename: samples/CAM_BACK_RIGHT/n015-2018-07-24-11-22-45+0800__CAM_BACK_RIGHT__1532402927627893.jpg\n",
       "   ego_pose_token: 79dbb4460a6b40f49f9c150cb118247e\n",
       "   calibrated_sensor_token: 3b00acc55ed941fa9f405e0c1fd2b639\n",
       " },\n",
       " SampleData {\n",
       "   token: 03bea5763f0f4722933508d5999c5fd8\n",
       "   sample_token: ca9a282c9e77460f8360f564131a8af5\n",
       "   filename: samples/CAM_BACK/n015-2018-07-24-11-22-45+0800__CAM_BACK__1532402927637525.jpg\n",
       "   ego_pose_token: 03bea5763f0f4722933508d5999c5fd8\n",
       "   calibrated_sensor_token: 4ff47c4950f04cb4be1876bc0b028326\n",
       " },\n",
       " SampleData {\n",
       "   token: 43893a033f9c46d4a51b5e08a67a1eb7\n",
       "   sample_token: ca9a282c9e77460f8360f564131a8af5\n",
       "   filename: samples/CAM_BACK_LEFT/n015-2018-07-24-11-22-45+0800__CAM_BACK_LEFT__1532402927647423.jpg\n",
       "   ego_pose_token: 43893a033f9c46d4a51b5e08a67a1eb7\n",
       "   calibrated_sensor_token: 3bc29be787ea4fc79144c4a46a3c91ca\n",
       " },\n",
       " SampleData {\n",
       "   token: fe5422747a7d4268a4b07fc396707b23\n",
       "   sample_token: ca9a282c9e77460f8360f564131a8af5\n",
       "   filename: samples/CAM_FRONT_LEFT/n015-2018-07-24-11-22-45+0800__CAM_FRONT_LEFT__1532402927604844.jpg\n",
       "   ego_pose_token: fe5422747a7d4268a4b07fc396707b23\n",
       "   calibrated_sensor_token: 75ad8e2a8a3f4594a13db2398430d097\n",
       " }]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_sample.datas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. `sample_annotation`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sample_annotation` refers to any ***bounding box defining the position of an object seen in a sample***. All location data is given with respect to the global coordinate system. Let's examine an example from our `sample` above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Annotation {\n",
       "  token: 83d881a6b3d94ef3a3bc3b585cc514f8\n",
       "  sample_token: ca9a282c9e77460f8360f564131a8af5\n",
       "  instance_token: e91afa15647c4c4994f19aeb302c7179\n",
       "  visibility_token: 4\n",
       "  attribute_tokens: [  58aa28b1c2a54dc88e169808c07331e3,   ]\n",
       "  translation:   Translation {\n",
       "    [409.989000, 1164.099000, 1.623000,     ]\n",
       "  }\n",
       "  rotation:   Rotation {\n",
       "    [-0.582882, 0.000000, 0.000000, 0.812557,     ]\n",
       "  }\n",
       "  size: [2.877000, 10.201000, 3.595000,   ]\n",
       "  prev_token: \n",
       "  next_token: f3721bdfd7ee4fd2a4f94874286df471\n",
       "}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_annotation_token = my_sample.annotations[18].token\n",
    "my_annotation_metadata =  nusc.annotation(my_annotation_token)\n",
    "my_annotation_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. `instance`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Object instance are instances that need to be detected or tracked by an AV (e.g a particular vehicle, pedestrian). Let us examine an instance metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Instance {\n",
       "  token: 9cba9cd8af85487fb010652c90d845b5\n",
       "  category_token: fedb11688db84088883945752e480c2c\n",
       "  nbr_annotations: 16\n",
       "}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_instance = nusc.instances[599]\n",
    "my_instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generally track an instance across different frames in a particular scene. However, we do not track them across different scenes. In this example, we have 16 annotated samples for this instance across a particular scene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_token = my_instance.token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. `category`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `category` is the object assignment of an annotation.  Let's look at the category table we have in our database. The table contains the taxonomy of different object categories and also list the subcategories (delineated by a period). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Category {\n",
       "   token: 1fa93b757fc74fb197cdd60001ad8abf\n",
       "   name: human.pedestrian.adult\n",
       "   description: Adult subcategory.\n",
       " },\n",
       " Category {\n",
       "   token: b1c6de4c57f14a5383d9f963fbdcb5cb\n",
       "   name: human.pedestrian.child\n",
       "   description: Child subcategory.\n",
       " },\n",
       " Category {\n",
       "   token: b2d7c6c701254928a9e4d6aac9446d79\n",
       "   name: human.pedestrian.wheelchair\n",
       "   description: Wheelchairs. If a person is in the wheelchair, include in the annotation.\n",
       " },\n",
       " Category {\n",
       "   token: 6a5888777ca14867a8aee3fe539b56c4\n",
       "   name: human.pedestrian.stroller\n",
       "   description: Strollers. If a person is in the stroller, include in the annotation.\n",
       " },\n",
       " Category {\n",
       "   token: 403fede16c88426885dd73366f16c34a\n",
       "   name: human.pedestrian.personal_mobility\n",
       "   description: A small electric or self-propelled vehicle, e.g. skateboard, segway, or scooters, on which the person typically travels in a upright position. Driver and (if applicable) rider should be included in the bounding box along with the vehicle.\n",
       " },\n",
       " Category {\n",
       "   token: bb867e2064014279863c71a29b1eb381\n",
       "   name: human.pedestrian.police_officer\n",
       "   description: Police officer.\n",
       " },\n",
       " Category {\n",
       "   token: 909f1237d34a49d6bdd27c2fe4581d79\n",
       "   name: human.pedestrian.construction_worker\n",
       "   description: Construction worker\n",
       " },\n",
       " Category {\n",
       "   token: 63a94dfa99bb47529567cd90d3b58384\n",
       "   name: animal\n",
       "   description: All animals, e.g. cats, rats, dogs, deer, birds.\n",
       " },\n",
       " Category {\n",
       "   token: fd69059b62a3469fbaef25340c0eab7f\n",
       "   name: vehicle.car\n",
       "   description: Vehicle designed primarily for personal use, e.g. sedans, hatch-backs, wagons, vans, mini-vans, SUVs and jeeps. If the vehicle is designed to carry more than 10 people use vehicle.bus. If it is primarily designed to haul cargo use vehicle.truck. \n",
       " },\n",
       " Category {\n",
       "   token: dfd26f200ade4d24b540184e16050022\n",
       "   name: vehicle.motorcycle\n",
       "   description: Gasoline or electric powered 2-wheeled vehicle designed to move rapidly (at the speed of standard cars) on the road surface. This category includes all motorcycles, vespas and scooters.\n",
       " },\n",
       " Category {\n",
       "   token: fc95c87b806f48f8a1faea2dcc2222a4\n",
       "   name: vehicle.bicycle\n",
       "   description: Human or electric powered 2-wheeled vehicle designed to travel at lower speeds either on road surface, sidewalks or bike paths.\n",
       " },\n",
       " Category {\n",
       "   token: 003edbfb9ca849ee8a7496e9af3025d4\n",
       "   name: vehicle.bus.bendy\n",
       "   description: Bendy bus subcategory. Annotate each section of the bendy bus individually.\n",
       " },\n",
       " Category {\n",
       "   token: fedb11688db84088883945752e480c2c\n",
       "   name: vehicle.bus.rigid\n",
       "   description: Rigid bus subcategory.\n",
       " },\n",
       " Category {\n",
       "   token: 6021b5187b924d64be64a702e5570edf\n",
       "   name: vehicle.truck\n",
       "   description: Vehicles primarily designed to haul cargo including pick-ups, lorrys, trucks and semi-tractors. Trailers hauled after a semi-tractor should be labeled as vehicle.trailer\n",
       " },\n",
       " Category {\n",
       "   token: 5b3cd6f2bca64b83aa3d0008df87d0e4\n",
       "   name: vehicle.construction\n",
       "   description: Vehicles primarily designed for construction. Typically very slow moving or stationary. Cranes and extremities of construction vehicles are only included in annotations if they interfere with traffic. Trucks used to haul rocks or building materials are considered vehicle.truck rather than construction vehicles.\n",
       " },\n",
       " Category {\n",
       "   token: 732cce86872640628788ff1bb81006d4\n",
       "   name: vehicle.emergency.ambulance\n",
       "   description: All types of ambulances.\n",
       " },\n",
       " Category {\n",
       "   token: 7b2ff083a64e4d53809ae5d9be563504\n",
       "   name: vehicle.emergency.police\n",
       "   description: All types of police vehicles including police bicycles and motorcycles.\n",
       " },\n",
       " Category {\n",
       "   token: 90d0f6f8e7c749149b1b6c3a029841a8\n",
       "   name: vehicle.trailer\n",
       "   description: Any vehicle trailer, both for trucks, cars and bikes.\n",
       " },\n",
       " Category {\n",
       "   token: 653f7efbb9514ce7b81d44070d6208c1\n",
       "   name: movable_object.barrier\n",
       "   description: Temporary road barrier placed in the scene in order to redirect traffic. Commonly used at construction sites. This includes concrete barrier, metal barrier and water barrier. No fences.\n",
       " },\n",
       " Category {\n",
       "   token: 85abebdccd4d46c7be428af5a6173947\n",
       "   name: movable_object.trafficcone\n",
       "   description: All types of traffic cone.\n",
       " },\n",
       " Category {\n",
       "   token: d772e4bae20f493f98e15a76518b31d7\n",
       "   name: movable_object.pushable_pullable\n",
       "   description: Objects that a pedestrian may push or pull. For example dolleys, wheel barrows, garbage-bins, or shopping carts.\n",
       " },\n",
       " Category {\n",
       "   token: 063c5e7f638343d3a7230bc3641caf97\n",
       "   name: movable_object.debris\n",
       "   description: Movable object that is left on the driveable surface that is too large to be driven over safely, e.g tree branch, full trash bag etc.\n",
       " },\n",
       " Category {\n",
       "   token: 0a30519ee16a4619b4f4acfe2d78fb55\n",
       "   name: static_object.bicycle_rack\n",
       "   description: Area or device intended to park or secure the bicycles in a row. It includes all the bikes parked in it and any empty slots that are intended for parking bikes.\n",
       " }]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nusc.categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A category record contains the name and the description of that particular category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category {\n",
       "  token: dfd26f200ade4d24b540184e16050022\n",
       "  name: vehicle.motorcycle\n",
       "  description: Gasoline or electric powered 2-wheeled vehicle designed to move rapidly (at the speed of standard cars) on the road surface. This category includes all motorcycles, vespas and scooters.\n",
       "}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nusc.categories[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer to `instructions_nuscenes.md` for the definitions of the different categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. `attribute`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An `attribute` is a property of an instance that may change throughout different parts of a scene while the category remains the same. Here we list the provided attributes and the number of annotations associated with a particular attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Attribute {\n",
       "   token: cb5118da1ab342aa947717dc53544259\n",
       "   name: vehicle.moving\n",
       "   description: Vehicle is moving.\n",
       " },\n",
       " Attribute {\n",
       "   token: c3246a1e22a14fcb878aa61e69ae3329\n",
       "   name: vehicle.stopped\n",
       "   description: Vehicle, with a driver/rider in/on it, is currently stationary but has an intent to move.\n",
       " },\n",
       " Attribute {\n",
       "   token: 58aa28b1c2a54dc88e169808c07331e3\n",
       "   name: vehicle.parked\n",
       "   description: Vehicle is stationary (usually for longer duration) with no immediate intent to move.\n",
       " },\n",
       " Attribute {\n",
       "   token: a14936d865eb4216b396adae8cb3939c\n",
       "   name: cycle.with_rider\n",
       "   description: There is a rider on the bicycle or motorcycle.\n",
       " },\n",
       " Attribute {\n",
       "   token: 5a655f9751944309a277276b8f473452\n",
       "   name: cycle.without_rider\n",
       "   description: There is NO rider on the bicycle or motorcycle.\n",
       " },\n",
       " Attribute {\n",
       "   token: 03aa62109bf043afafdea7d875dd4f43\n",
       "   name: pedestrian.sitting_lying_down\n",
       "   description: The human is sitting or lying down.\n",
       " },\n",
       " Attribute {\n",
       "   token: 4d8821270b4a47e3a8a300cbec48188e\n",
       "   name: pedestrian.standing\n",
       "   description: The human is standing.\n",
       " },\n",
       " Attribute {\n",
       "   token: ab83627ff28b465b85c427162dec722f\n",
       "   name: pedestrian.moving\n",
       "   description: The human is moving.\n",
       " }]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nusc.attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at an example how an attribute may change over one scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed from `None` to `pedestrian.moving` at timestamp 1532402927647951 out of 39 annotated timestamps\n",
      "Changed from `pedestrian.moving` to `pedestrian.standing` at timestamp 1532402938197897 out of 39 annotated timestamps\n"
     ]
    }
   ],
   "source": [
    "my_instance = nusc.instances[27]\n",
    "first_token = my_instance.first_annotation_token\n",
    "last_token = my_instance.last_annotation_token\n",
    "nbr_samples = my_instance.nbr_annotations\n",
    "current_token = first_token\n",
    "\n",
    "found_change = False\n",
    "last_attr = None\n",
    "for ann in my_instance.annotations:\n",
    "    cur_attr_token = ann.attribute_tokens[0]\n",
    "    cur_attr = nusc.attribute(cur_attr_token).name\n",
    "    if cur_attr != last_attr:\n",
    "        print(\"Changed from `{}` to `{}` at timestamp {} out of {} annotated timestamps\".format(last_attr, cur_attr, ann.sample.timestamp, nbr_samples))\n",
    "        found_change = True\n",
    "    last_attr = cur_attr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. `visibility`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`visibility` is defined as the fraction of pixels of a particular annotation that are visible over the 6 camera feeds, grouped into 4 bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Visibility {\n",
       "   token: 1\n",
       "   name: v0-40\n",
       "   description: visibility of whole object is between 0 and 40%\n",
       " },\n",
       " Visibility {\n",
       "   token: 2\n",
       "   name: v40-60\n",
       "   description: visibility of whole object is between 40 and 60%\n",
       " },\n",
       " Visibility {\n",
       "   token: 3\n",
       "   name: v60-80\n",
       "   description: visibility of whole object is between 60 and 80%\n",
       " },\n",
       " Visibility {\n",
       "   token: 4\n",
       "   name: v80-100\n",
       "   description: visibility of whole object is between 80 and 100%\n",
       " }]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nusc.visibilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at an example `sample_annotation` with 80-100% visibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visibility: 4\n"
     ]
    }
   ],
   "source": [
    "anntoken = 'a7d0722bce164f88adf03ada491ea0ba'\n",
    "visibility = nusc.annotation(anntoken).visibility_token\n",
    "\n",
    "print(f\"Visibility: {visibility}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at an example `sample_annotation` with 0-40% visibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visibility: 1\n"
     ]
    }
   ],
   "source": [
    "anntoken = '9f450bf6b7454551bbbc9a4c6e74ef2e'\n",
    "visibility_token = nusc.annotation(anntoken).visibility_token\n",
    "visibility = nusc.visibility(visibility_token).token\n",
    "\n",
    "print(f\"Visibility: {visibility}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. `sensor`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nuScenes dataset consists of data collected from our full sensor suite which consists of:\n",
    "- 1 x LIDAR, \n",
    "- 5 x RADAR, \n",
    "- 6 x cameras, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sensor {\n",
       "   token: 725903f5b62f56118f4094b46a4470d8\n",
       "   channel: CAM_FRONT\n",
       "   modality: camera\n",
       "   channel: CAM_FRONT\n",
       "   channel: CAM_FRONT\n",
       " },\n",
       " Sensor {\n",
       "   token: ce89d4f3050b5892b33b3d328c5e82a3\n",
       "   channel: CAM_BACK\n",
       "   modality: camera\n",
       "   channel: CAM_BACK\n",
       "   channel: CAM_BACK\n",
       " },\n",
       " Sensor {\n",
       "   token: a89643a5de885c6486df2232dc954da2\n",
       "   channel: CAM_BACK_LEFT\n",
       "   modality: camera\n",
       "   channel: CAM_BACK_LEFT\n",
       "   channel: CAM_BACK_LEFT\n",
       " },\n",
       " Sensor {\n",
       "   token: ec4b5d41840a509984f7ec36419d4c09\n",
       "   channel: CAM_FRONT_LEFT\n",
       "   modality: camera\n",
       "   channel: CAM_FRONT_LEFT\n",
       "   channel: CAM_FRONT_LEFT\n",
       " },\n",
       " Sensor {\n",
       "   token: 2f7ad058f1ac5557bf321c7543758f43\n",
       "   channel: CAM_FRONT_RIGHT\n",
       "   modality: camera\n",
       "   channel: CAM_FRONT_RIGHT\n",
       "   channel: CAM_FRONT_RIGHT\n",
       " },\n",
       " Sensor {\n",
       "   token: ca7dba2ec9f95951bbe67246f7f2c3f7\n",
       "   channel: CAM_BACK_RIGHT\n",
       "   modality: camera\n",
       "   channel: CAM_BACK_RIGHT\n",
       "   channel: CAM_BACK_RIGHT\n",
       " },\n",
       " Sensor {\n",
       "   token: dc8b396651c05aedbb9cdaae573bb567\n",
       "   channel: LIDAR_TOP\n",
       "   modality: lidar\n",
       "   channel: LIDAR_TOP\n",
       "   channel: LIDAR_TOP\n",
       " },\n",
       " Sensor {\n",
       "   token: 47fcd48f71d75e0da5c8c1704a9bfe0a\n",
       "   channel: RADAR_FRONT\n",
       "   modality: radar\n",
       "   channel: RADAR_FRONT\n",
       "   channel: RADAR_FRONT\n",
       " },\n",
       " Sensor {\n",
       "   token: 232a6c4dc628532e81de1c57120876e9\n",
       "   channel: RADAR_FRONT_RIGHT\n",
       "   modality: radar\n",
       "   channel: RADAR_FRONT_RIGHT\n",
       "   channel: RADAR_FRONT_RIGHT\n",
       " },\n",
       " Sensor {\n",
       "   token: 1f69f87a4e175e5ba1d03e2e6d9bcd27\n",
       "   channel: RADAR_FRONT_LEFT\n",
       "   modality: radar\n",
       "   channel: RADAR_FRONT_LEFT\n",
       "   channel: RADAR_FRONT_LEFT\n",
       " },\n",
       " Sensor {\n",
       "   token: df2d5b8be7be55cca33c8c92384f2266\n",
       "   channel: RADAR_BACK_LEFT\n",
       "   modality: radar\n",
       "   channel: RADAR_BACK_LEFT\n",
       "   channel: RADAR_BACK_LEFT\n",
       " },\n",
       " Sensor {\n",
       "   token: 5c29dee2f70b528a817110173c2e71b9\n",
       "   channel: RADAR_BACK_RIGHT\n",
       "   modality: radar\n",
       "   channel: RADAR_BACK_RIGHT\n",
       "   channel: RADAR_BACK_RIGHT\n",
       " }]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nusc.sensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every `sample_data` has a record on which `sensor` the data is collected from (note the \"channel\" key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SampleData {\n",
       "  token: 2ecfec536d984fb491098c9db1404117\n",
       "  sample_token: 356d81f38dd9473ba590f39e266f54e5\n",
       "  filename: sweeps/RADAR_FRONT/n015-2018-07-24-11-22-45+0800__RADAR_FRONT__1532402928269133.pcd\n",
       "  ego_pose_token: 2ecfec536d984fb491098c9db1404117\n",
       "  calibrated_sensor_token: f4d2a6c281f34a7eb8bb033d82321f79\n",
       "}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nusc.sample_datas[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. `calibrated_sensor`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`calibrated_sensor` consists of the definition of a particular sensor (lidar/radar/camera) as calibrated on a particular vehicle. Let us look at an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CalibratedSensor {\n",
       "  token: f4d2a6c281f34a7eb8bb033d82321f79\n",
       "  sensor_token: 47fcd48f71d75e0da5c8c1704a9bfe0a\n",
       "}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nusc.calibrated_sensors[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `translation` and the `rotation` parameters are given with respect to the ego vehicle body frame. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. `ego_pose`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ego_pose` contains information about the location (encoded in `translation`) and the orientation (encoded in `rotation`) of the ego vehicle, with respect to the global coordinate system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EgoPosition {\n",
       "  token: 5ace90b379af485b9dcb1584b01e7212\n",
       "  timestamp: 1532402927814384\n",
       "  translation:   Translation {\n",
       "    [410.778786, 1179.467329, 0.000000,     ]\n",
       "  }\n",
       "  rotation:   Rotation {\n",
       "    [0.573179, -0.001581, 0.013859, -0.819312,     ]\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nusc.ego_positions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the number of `ego_pose` records in our loaded database is the same as the number of `sample_data` records. These two records exhibit a one-to-one correspondence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. `log`\n",
    "\n",
    "The `log` table contains log information from which the data was extracted. A `log` record corresponds to one journey of our ego vehicle along a predefined route. Let's check the number of logs and the metadata of a log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of `logs` in our loaded database: 8\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of `logs` in our loaded database: {}\".format(len(nusc.logs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Log {\n",
       "  token: 7e25a2c8ea1f41c5b0da1e69ecfa71a2\n",
       "  logfile: n015-2018-07-24-11-22-45+0800\n",
       "  vehicle: n015\n",
       "  date_captured: 2018-07-24\n",
       "}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nusc.logs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that it contains a variety of information such as the date and location of the log collected. It also gives out information about the map from where the data was collected. Note that one log can contain multiple non-overlapping scenes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. `map`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map information is stored as binary semantic masks from a top-down view. Let's check the number of maps and metadata of a map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4 maps masks in the loaded dataset\n"
     ]
    }
   ],
   "source": [
    "print(\"There are {} maps masks in the loaded dataset\".format(len(nusc.maps)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map {\n",
       "  token: 53992ee3023e5494b90c316c183be829\n",
       "  filename: maps/53992ee3023e5494b90c316c183be829.png\n",
       "}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nusc.maps[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nuScenes Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a bit technical.\n",
    "\n",
    "The NuScenes class holds several tables. Each table is a list of records, and each record is a dictionary. For example the first record of the category table is stored at:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category {\n",
       "  token: 1fa93b757fc74fb197cdd60001ad8abf\n",
       "  name: human.pedestrian.adult\n",
       "  description: Adult subcategory.\n",
       "}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nusc.categories[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The category table is simple: it holds the fields `name` and `description`. It also has a `token` field, which is a unique record identifier. Since the record is a dictionary, the token can be accessed like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1fa93b757fc74fb197cdd60001ad8abf'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_token = nusc.categories[0].token\n",
    "cat_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you know the `token` for any record in the DB you can retrieve the record by doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category {\n",
       "  token: 1fa93b757fc74fb197cdd60001ad8abf\n",
       "  name: human.pedestrian.adult\n",
       "  description: Adult subcategory.\n",
       "}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nusc.category(cat_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_As you can notice, we have recovered the same record!_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, that was easy. Let's try something harder. Let's look at the `sample_annotation` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Annotation {\n",
       "  token: 70aecbe9b64f4722ab3c230391a3beb8\n",
       "  sample_token: cd21dbfc3bd749c7b10a5c42562e0c42\n",
       "  instance_token: 6dd2cbf4c24b4caeb625035869bca7b5\n",
       "  visibility_token: 4\n",
       "  attribute_tokens: [  4d8821270b4a47e3a8a300cbec48188e,   ]\n",
       "  translation:   Translation {\n",
       "    [373.214000, 1130.480000, 1.250000,     ]\n",
       "  }\n",
       "  rotation:   Rotation {\n",
       "    [0.983110, 0.000000, 0.000000, -0.183016,     ]\n",
       "  }\n",
       "  size: [0.621000, 0.669000, 1.642000,   ]\n",
       "  prev_token: a1721876c0944cdd92ebc3c75d55d693\n",
       "  next_token: 1e8e35d365a441a18dd5503a0ee1c208\n",
       "}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nusc.annotations[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This also has a `token` field (they all do). In addition, it has several fields of the format [a-z]*\\_token, _e.g._ instance_token. These are foreign keys in database terminology, meaning they point to another table. \n",
    "Using `nusc.get()` we can grab any of these in constant time. For example, let's look at the visibility record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Visibility {\n",
       "  token: 4\n",
       "  name: v80-100\n",
       "  description: visibility of whole object is between 80 and 100%\n",
       "}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nusc.visibility(nusc.annotations[0].visibility_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The visibility records indicate how much of an object was visible when it was annotated.\n",
    "\n",
    "Let's also grab the `instance_token`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Instance {\n",
       "  token: 6dd2cbf4c24b4caeb625035869bca7b5\n",
       "  category_token: 1fa93b757fc74fb197cdd60001ad8abf\n",
       "  nbr_annotations: 39\n",
       "}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_instance = nusc.instance(nusc.annotations[0].instance_token)\n",
    "one_instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This points to the `instance` table. This table enumerate the object _instances_ we have encountered in each \n",
    "scene. This way we can connect all annotations of a particular object.\n",
    "\n",
    "If you look carefully at the README tables, you will see that the sample_annotation table points to the instance table, \n",
    "but the instance table doesn't list all annotations that point to it. \n",
    "\n",
    "So how can we recover all sample_annotations for a particular object instance? There are two ways:\n",
    "\n",
    "1. Directly use `instance.annotations`. Let's try it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Annotation {\n",
       "   token: ef63a697930c4b20a6b9791f423351da\n",
       "   sample_token: ca9a282c9e77460f8360f564131a8af5\n",
       "   instance_token: 6dd2cbf4c24b4caeb625035869bca7b5\n",
       "   visibility_token: 1\n",
       "   attribute_tokens: [  4d8821270b4a47e3a8a300cbec48188e,   ]\n",
       "   translation:   Translation {\n",
       "     [373.256000, 1130.419000, 0.800000,     ]\n",
       "   }\n",
       "   rotation:   Rotation {\n",
       "     [0.983110, 0.000000, 0.000000, -0.183016,     ]\n",
       "   }\n",
       "   size: [0.621000, 0.669000, 1.642000,   ]\n",
       "   prev_token: \n",
       "   next_token: 7987617983634b119e383d8a29607fd7\n",
       " },\n",
       " Annotation {\n",
       "   token: 7987617983634b119e383d8a29607fd7\n",
       "   sample_token: 39586f9d59004284a7114a68825e8eec\n",
       "   instance_token: 6dd2cbf4c24b4caeb625035869bca7b5\n",
       "   visibility_token: 1\n",
       "   attribute_tokens: [  4d8821270b4a47e3a8a300cbec48188e,   ]\n",
       "   translation:   Translation {\n",
       "     [373.256000, 1130.419000, 0.810000,     ]\n",
       "   }\n",
       "   rotation:   Rotation {\n",
       "     [0.983110, 0.000000, 0.000000, -0.183016,     ]\n",
       "   }\n",
       "   size: [0.621000, 0.669000, 1.642000,   ]\n",
       "   prev_token: ef63a697930c4b20a6b9791f423351da\n",
       "   next_token: 9acb7dfed3454f72b2874dda3bdacc48\n",
       " },\n",
       " Annotation {\n",
       "   token: 9acb7dfed3454f72b2874dda3bdacc48\n",
       "   sample_token: 356d81f38dd9473ba590f39e266f54e5\n",
       "   instance_token: 6dd2cbf4c24b4caeb625035869bca7b5\n",
       "   visibility_token: 1\n",
       "   attribute_tokens: [  4d8821270b4a47e3a8a300cbec48188e,   ]\n",
       "   translation:   Translation {\n",
       "     [373.256000, 1130.419000, 0.820000,     ]\n",
       "   }\n",
       "   rotation:   Rotation {\n",
       "     [0.983110, 0.000000, 0.000000, -0.183016,     ]\n",
       "   }\n",
       "   size: [0.621000, 0.669000, 1.642000,   ]\n",
       "   prev_token: 7987617983634b119e383d8a29607fd7\n",
       "   next_token: 74f550e3257c4f52af1102c0d49d37b8\n",
       " },\n",
       " Annotation {\n",
       "   token: 74f550e3257c4f52af1102c0d49d37b8\n",
       "   sample_token: e0845f5322254dafadbbed75aaa07969\n",
       "   instance_token: 6dd2cbf4c24b4caeb625035869bca7b5\n",
       "   visibility_token: 1\n",
       "   attribute_tokens: [  4d8821270b4a47e3a8a300cbec48188e,   ]\n",
       "   translation:   Translation {\n",
       "     [373.256000, 1130.419000, 0.830000,     ]\n",
       "   }\n",
       "   rotation:   Rotation {\n",
       "     [0.983110, 0.000000, 0.000000, -0.183016,     ]\n",
       "   }\n",
       "   size: [0.621000, 0.669000, 1.642000,   ]\n",
       "   prev_token: 9acb7dfed3454f72b2874dda3bdacc48\n",
       "   next_token: 060be69422ee4b2a8b239b463b995e92\n",
       " },\n",
       " Annotation {\n",
       "   token: 060be69422ee4b2a8b239b463b995e92\n",
       "   sample_token: c923fe08b2ff4e27975d2bf30934383b\n",
       "   instance_token: 6dd2cbf4c24b4caeb625035869bca7b5\n",
       "   visibility_token: 2\n",
       "   attribute_tokens: [  4d8821270b4a47e3a8a300cbec48188e,   ]\n",
       "   translation:   Translation {\n",
       "     [373.256000, 1130.419000, 0.840000,     ]\n",
       "   }\n",
       "   rotation:   Rotation {\n",
       "     [0.983110, 0.000000, 0.000000, -0.183016,     ]\n",
       "   }\n",
       "   size: [0.621000, 0.669000, 1.642000,   ]\n",
       "   prev_token: 74f550e3257c4f52af1102c0d49d37b8\n",
       "   next_token: a2b20cdbf1ed4018ac795b8845d5deaa\n",
       " },\n",
       " Annotation {\n",
       "   token: a2b20cdbf1ed4018ac795b8845d5deaa\n",
       "   sample_token: f1e3d9d08f044c439ce86a2d6fcca57b\n",
       "   instance_token: 6dd2cbf4c24b4caeb625035869bca7b5\n",
       "   visibility_token: 1\n",
       "   attribute_tokens: [  4d8821270b4a47e3a8a300cbec48188e,   ]\n",
       "   translation:   Translation {\n",
       "     [373.256000, 1130.419000, 0.792000,     ]\n",
       "   }\n",
       "   rotation:   Rotation {\n",
       "     [0.983110, 0.000000, 0.000000, -0.183016,     ]\n",
       "   }\n",
       "   size: [0.621000, 0.669000, 1.642000,   ]\n",
       "   prev_token: 060be69422ee4b2a8b239b463b995e92\n",
       "   next_token: 05e0ad1194804f548be544f2267c7e74\n",
       " },\n",
       " Annotation {\n",
       "   token: 05e0ad1194804f548be544f2267c7e74\n",
       "   sample_token: 4f545737bf3347fbbc9af60b0be9a963\n",
       "   instance_token: 6dd2cbf4c24b4caeb625035869bca7b5\n",
       "   visibility_token: 1\n",
       "   attribute_tokens: [  4d8821270b4a47e3a8a300cbec48188e,   ]\n",
       "   translation:   Translation {\n",
       "     [373.256000, 1130.419000, 0.744000,     ]\n",
       "   }\n",
       "   rotation:   Rotation {\n",
       "     [0.983110, 0.000000, 0.000000, -0.183016,     ]\n",
       "   }\n",
       "   size: [0.621000, 0.669000, 1.642000,   ]\n",
       "   prev_token: a2b20cdbf1ed4018ac795b8845d5deaa\n",
       "   next_token: d15155fecf2f440c97bb0781777e18d4\n",
       " },\n",
       " Annotation {\n",
       "   token: d15155fecf2f440c97bb0781777e18d4\n",
       "   sample_token: 7626dde27d604ac28a0240bdd54eba7a\n",
       "   instance_token: 6dd2cbf4c24b4caeb625035869bca7b5\n",
       "   visibility_token: 1\n",
       "   attribute_tokens: [  4d8821270b4a47e3a8a300cbec48188e,   ]\n",
       "   translation:   Translation {\n",
       "     [373.256000, 1130.419000, 0.695000,     ]\n",
       "   }\n",
       "   rotation:   Rotation {\n",
       "     [0.983110, 0.000000, 0.000000, -0.183016,     ]\n",
       "   }\n",
       "   size: [0.621000, 0.669000, 1.642000,   ]\n",
       "   prev_token: 05e0ad1194804f548be544f2267c7e74\n",
       "   next_token: 4e41d9560dbf46cab1568b8ef6a282f3\n",
       " },\n",
       " Annotation {\n",
       "   token: 4e41d9560dbf46cab1568b8ef6a282f3\n",
       "   sample_token: be99ffc878b24aca8956bbb4e0f97d0c\n",
       "   instance_token: 6dd2cbf4c24b4caeb625035869bca7b5\n",
       "   visibility_token: 1\n",
       "   attribute_tokens: [  4d8821270b4a47e3a8a300cbec48188e,   ]\n",
       "   translation:   Translation {\n",
       "     [373.256000, 1130.419000, 0.647000,     ]\n",
       "   }\n",
       "   rotation:   Rotation {\n",
       "     [0.983110, 0.000000, 0.000000, -0.183016,     ]\n",
       "   }\n",
       "   size: [0.621000, 0.669000, 1.642000,   ]\n",
       "   prev_token: d15155fecf2f440c97bb0781777e18d4\n",
       "   next_token: 1de9ad564050444486eb587360cf135f\n",
       " },\n",
       " Annotation {\n",
       "   token: 1de9ad564050444486eb587360cf135f\n",
       "   sample_token: 9813c23a5f1448b09bb7910fea9baf20\n",
       "   instance_token: 6dd2cbf4c24b4caeb625035869bca7b5\n",
       "   visibility_token: 1\n",
       "   attribute_tokens: [  4d8821270b4a47e3a8a300cbec48188e,   ]\n",
       "   translation:   Translation {\n",
       "     [373.256000, 1130.419000, 0.599000,     ]\n",
       "   }\n",
       "   rotation:   Rotation {\n",
       "     [0.983110, 0.000000, 0.000000, -0.183016,     ]\n",
       "   }\n",
       "   size: [0.621000, 0.669000, 1.642000,   ]\n",
       "   prev_token: 4e41d9560dbf46cab1568b8ef6a282f3\n",
       "   next_token: ed72884bda8a4332bbcb80c285a97929\n",
       " },\n",
       " Annotation {\n",
       "   token: ed72884bda8a4332bbcb80c285a97929\n",
       "   sample_token: 023c4df2d451409881d8e6ea82f14704\n",
       "   instance_token: 6dd2cbf4c24b4caeb625035869bca7b5\n",
       "   visibility_token: 1\n",
       "   attribute_tokens: [  4d8821270b4a47e3a8a300cbec48188e,   ]\n",
       "   translation:   Translation {\n",
       "     [373.256000, 1130.419000, 0.550000,     ]\n",
       "   }\n",
       "   rotation:   Rotation {\n",
       "     [0.983110, 0.000000, 0.000000, -0.183016,     ]\n",
       "   }\n",
       "   size: [0.621000, 0.669000, 1.642000,   ]\n",
       "   prev_token: 1de9ad564050444486eb587360cf135f\n",
       "   next_token: a72013a0352a496c9a01832f5666ae31\n",
       " },\n",
       " Annotation {\n",
       "   token: a72013a0352a496c9a01832f5666ae31\n",
       "   sample_token: c235638ed66145988d17f9d0601923f2\n",
       "   instance_token: 6dd2cbf4c24b4caeb625035869bca7b5\n",
       "   visibility_token: 1\n",
       "   attribute_tokens: [  4d8821270b4a47e3a8a300cbec48188e,   ]\n",
       "   translation:   Translation {\n",
       "     [373.256000, 1130.419000, 0.750000,     ]\n",
       "   }\n",
       "   rotation:   Rotation {\n",
       "     [0.983110, 0.000000, 0.000000, -0.183016,     ]\n",
       "   }\n",
       "   size: [0.621000, 0.669000, 1.642000,   ]\n",
       "   prev_token: ed72884bda8a4332bbcb80c285a97929\n",
       "   next_token: 23f10d5f0d254068941be8797493c7eb\n",
       " },\n",
       " Annotation {\n",
       "   token: 23f10d5f0d254068941be8797493c7eb\n",
       "   sample_token: bc3c8a953f6b4dcdb77b521d89f3d9d5\n",
       "   instance_token: 6dd2cbf4c24b4caeb625035869bca7b5\n",
       "   visibility_token: 1\n",
       "   attribute_tokens: [  4d8821270b4a47e3a8a300cbec48188e,   ]\n",
       "   translation:   Translation {\n",
       "     [373.256000, 1130.419000, 0.950000,     ]\n",
       "   }\n",
       "   rotation:   Rotation {\n",
       "     [0.983110, 0.000000, 0.000000, -0.183016,     ]\n",
       "   }\n",
       "   size: [0.621000, 0.669000, 1.642000,   ]\n",
       "   prev_token: a72013a0352a496c9a01832f5666ae31\n",
       "   next_token: b38209aa7b0c49a5b910e7b774b07bd5\n",
       " },\n",
       " Annotation {\n",
       "   token: b38209aa7b0c49a5b910e7b774b07bd5\n",
       "   sample_token: 1e3d79dae62742a0ad64c91679863358\n",
       "   instance_token: 6dd2cbf4c24b4caeb625035869bca7b5\n",
       "   visibility_token: 3\n",
       "   attribute_tokens: [  4d8821270b4a47e3a8a300cbec48188e,   ]\n",
       "   translation:   Translation {\n",
       "     [373.256000, 1130.419000, 1.000000,     ]\n",
       "   }\n",
       "   rotation:   Rotation {\n",
       "     [0.983110, 0.000000, 0.000000, -0.183016,     ]\n",
       "   }\n",
       "   size: [0.621000, 0.669000, 1.642000,   ]\n",
       "   prev_token: 23f10d5f0d254068941be8797493c7eb\n",
       "   next_token: a1721876c0944cdd92ebc3c75d55d693\n",
       " },\n",
       " Annotation {\n",
       "   token: a1721876c0944cdd92ebc3c75d55d693\n",
       "   sample_token: 2afb9d32310e4546a71cbe432911eca2\n",
       "   instance_token: 6dd2cbf4c24b4caeb625035869bca7b5\n",
       "   visibility_token: 4\n",
       "   attribute_tokens: [  4d8821270b4a47e3a8a300cbec48188e,   ]\n",
       "   translation:   Translation {\n",
       "     [373.256000, 1130.419000, 1.150000,     ]\n",
       "   }\n",
       "   rotation:   Rotation {\n",
       "     [0.983110, 0.000000, 0.000000, -0.183016,     ]\n",
       "   }\n",
       "   size: [0.621000, 0.669000, 1.642000,   ]\n",
       "   prev_token: b38209aa7b0c49a5b910e7b774b07bd5\n",
       "   next_token: 70aecbe9b64f4722ab3c230391a3beb8\n",
       " },\n",
       " Annotation {\n",
       "   token: 70aecbe9b64f4722ab3c230391a3beb8\n",
       "   sample_token: cd21dbfc3bd749c7b10a5c42562e0c42\n",
       "   instance_token: 6dd2cbf4c24b4caeb625035869bca7b5\n",
       "   visibility_token: 4\n",
       "   attribute_tokens: [  4d8821270b4a47e3a8a300cbec48188e,   ]\n",
       "   translation:   Translation {\n",
       "     [373.214000, 1130.480000, 1.250000,     ]\n",
       "   }\n",
       "   rotation:   Rotation {\n",
       "     [0.983110, 0.000000, 0.000000, -0.183016,     ]\n",
       "   }\n",
       "   size: [0.621000, 0.669000, 1.642000,   ]\n",
       "   prev_token: a1721876c0944cdd92ebc3c75d55d693\n",
       "   next_token: 1e8e35d365a441a18dd5503a0ee1c208\n",
       " },\n",
       " Annotation {\n",
       "   token: 1e8e35d365a441a18dd5503a0ee1c208\n",
       "   sample_token: 88449a5cb1644a199c1c11f6ac034867\n",
       "   instance_token: 6dd2cbf4c24b4caeb625035869bca7b5\n",
       "   visibility_token: 4\n",
       "   attribute_tokens: [  4d8821270b4a47e3a8a300cbec48188e,   ]\n",
       "   translation:   Translation {\n",
       "     [373.183000, 1130.419000, 1.250000,     ]\n",
       "   }\n",
       "   rotation:   Rotation {\n",
       "     [0.983110, 0.000000, 0.000000, -0.183016,     ]\n",
       "   }\n",
       "   size: [0.621000, 0.669000, 1.642000,   ]\n",
       "   prev_token: 70aecbe9b64f4722ab3c230391a3beb8\n",
       "   next_token: 7fa3a688931b4500b7ce29d187d3b975\n",
       " },\n",
       " Annotation {\n",
       "   token: 7fa3a688931b4500b7ce29d187d3b975\n",
       "   sample_token: 2ff86dc19c4644a1a88ce5ba848f56e5\n",
       "   instance_token: 6dd2cbf4c24b4caeb625035869bca7b5\n",
       "   visibility_token: 4\n",
       "   attribute_tokens: [  4d8821270b4a47e3a8a300cbec48188e,   ]\n",
       "   translation:   Translation {\n",
       "     [373.152000, 1130.357000, 1.250000,     ]\n",
       "   }\n",
       "   rotation:   Rotation {\n",
       "     [0.983110, 0.000000, 0.000000, -0.183016,     ]\n",
       "   }\n",
       "   size: [0.621000, 0.669000, 1.642000,   ]\n",
       "   prev_token: 1e8e35d365a441a18dd5503a0ee1c208\n",
       "   next_token: 913072e56d6c4025b9b47ba085dd6d7c\n",
       " },\n",
       " Annotation {\n",
       "   token: 913072e56d6c4025b9b47ba085dd6d7c\n",
       "   sample_token: bf2938e43c6f487497cda76b51bfc406\n",
       "   instance_token: 6dd2cbf4c24b4caeb625035869bca7b5\n",
       "   visibility_token: 1\n",
       "   attribute_tokens: [  4d8821270b4a47e3a8a300cbec48188e,   ]\n",
       "   translation:   Translation {\n",
       "     [373.180000, 1130.431000, 1.263000,     ]\n",
       "   }\n",
       "   rotation:   Rotation {\n",
       "     [0.983110, 0.000000, 0.000000, -0.183016,     ]\n",
       "   }\n",
       "   size: [0.621000, 0.669000, 1.642000,   ]\n",
       "   prev_token: 7fa3a688931b4500b7ce29d187d3b975\n",
       "   next_token: b8f593154b8144f58e1e53d3c91ab567\n",
       " },\n",
       " Annotation {\n",
       "   token: b8f593154b8144f58e1e53d3c91ab567\n",
       "   sample_token: b26e791522294bec90f86fd72226e35c\n",
       "   instance_token: 6dd2cbf4c24b4caeb625035869bca7b5\n",
       "   visibility_token: 1\n",
       "   attribute_tokens: [  4d8821270b4a47e3a8a300cbec48188e,   ]\n",
       "   translation:   Translation {\n",
       "     [373.208000, 1130.504000, 1.275000,     ]\n",
       "   }\n",
       "   rotation:   Rotation {\n",
       "     [0.983110, 0.000000, 0.000000, -0.183016,     ]\n",
       "   }\n",
       "   size: [0.621000, 0.669000, 1.642000,   ]\n",
       "   prev_token: 913072e56d6c4025b9b47ba085dd6d7c\n",
       "   next_token: f503fa3d050f43cca4af2241b674929a\n",
       " },\n",
       " Annotation {\n",
       "   token: f503fa3d050f43cca4af2241b674929a\n",
       "   sample_token: c844bf5a9f2243ff8f4bf2c85fe218ff\n",
       "   instance_token: 6dd2cbf4c24b4caeb625035869bca7b5\n",
       "   visibility_token: 1\n",
       "   attribute_tokens: [  4d8821270b4a47e3a8a300cbec48188e,   ]\n",
       "   translation:   Translation {\n",
       "     [373.237000, 1130.577000, 1.288000,     ]\n",
       "   }\n",
       "   rotation:   Rotation {\n",
       "     [0.983110, 0.000000, 0.000000, -0.183016,     ]\n",
       "   }\n",
       "   size: [0.621000, 0.669000, 1.642000,   ]\n",
       "   prev_token: b8f593154b8144f58e1e53d3c91ab567\n",
       "   next_token: e5fe9ea066254609b48eb073e81ef209\n",
       " },\n",
       " Annotation {\n",
       "   token: e5fe9ea066254609b48eb073e81ef209\n",
       "   sample_token: fedfb3a6cb804635a0f47143f9ca8d6f\n",
       "   instance_token: 6dd2cbf4c24b4caeb625035869bca7b5\n",
       "   visibility_token: 4\n",
       "   attribute_tokens: [  4d8821270b4a47e3a8a300cbec48188e,   ]\n",
       "   translation:   Translation {\n",
       "     [373.245000, 1130.600000, 1.300000,     ]\n",
       "   }\n",
       "   rotation:   Rotation {\n",
       "     [0.983110, 0.000000, 0.000000, -0.183016,     ]\n",
       "   }\n",
       "   size: [0.621000, 0.669000, 1.642000,   ]\n",
       "   prev_token: f503fa3d050f43cca4af2241b674929a\n",
       "   next_token: 2b5948828cdb49e3be6be1320381bbbf\n",
       " },\n",
       " Annotation {\n",
       "   token: 2b5948828cdb49e3be6be1320381bbbf\n",
       "   sample_token: 965f6af5a92449348409029a5f048a38\n",
       "   instance_token: 6dd2cbf4c24b4caeb625035869bca7b5\n",
       "   visibility_token: 4\n",
       "   attribute_tokens: [  4d8821270b4a47e3a8a300cbec48188e,   ]\n",
       "   translation:   Translation {\n",
       "     [373.245000, 1130.600000, 1.250000,     ]\n",
       "   }\n",
       "   rotation:   Rotation {\n",
       "     [0.983110, 0.000000, 0.000000, -0.183016,     ]\n",
       "   }\n",
       "   size: [0.621000, 0.669000, 1.642000,   ]\n",
       "   prev_token: e5fe9ea066254609b48eb073e81ef209\n",
       "   next_token: 17a6843fefcd4b2b811eddbb1ccd708d\n",
       " },\n",
       " Annotation {\n",
       "   token: 17a6843fefcd4b2b811eddbb1ccd708d\n",
       "   sample_token: 4711bcd34644420da8bc77163431888e\n",
       "   instance_token: 6dd2cbf4c24b4caeb625035869bca7b5\n",
       "   visibility_token: 1\n",
       "   attribute_tokens: [  4d8821270b4a47e3a8a300cbec48188e,   ]\n",
       "   translation:   Translation {\n",
       "     [373.245000, 1130.600000, 1.200000,     ]\n",
       "   }\n",
       "   rotation:   Rotation {\n",
       "     [0.983110, 0.000000, 0.000000, -0.183016,     ]\n",
       "   }\n",
       "   size: [0.621000, 0.669000, 1.642000,   ]\n",
       "   prev_token: 2b5948828cdb49e3be6be1320381bbbf\n",
       "   next_token: 146b2111cc0c401ca09d96777758d81e\n",
       " },\n",
       " Annotation {\n",
       "   token: 146b2111cc0c401ca09d96777758d81e\n",
       "   sample_token: a34fabc7aa674713b71f98ec541eb2d4\n",
       "   instance_token: 6dd2cbf4c24b4caeb625035869bca7b5\n",
       "   visibility_token: 1\n",
       "   attribute_tokens: [  4d8821270b4a47e3a8a300cbec48188e,   ]\n",
       "   translation:   Translation {\n",
       "     [373.245000, 1130.600000, 1.150000,     ]\n",
       "   }\n",
       "   rotation:   Rotation {\n",
       "     [0.983110, 0.000000, 0.000000, -0.183016,     ]\n",
       "   }\n",
       "   size: [0.621000, 0.669000, 1.642000,   ]\n",
       "   prev_token: 17a6843fefcd4b2b811eddbb1ccd708d\n",
       "   next_token: a2f1d09320c3454ba3f2347c4b5903a5\n",
       " },\n",
       " Annotation {\n",
       "   token: a2f1d09320c3454ba3f2347c4b5903a5\n",
       "   sample_token: c78067571d104caba7c568a847d56971\n",
       "   instance_token: 6dd2cbf4c24b4caeb625035869bca7b5\n",
       "   visibility_token: 3\n",
       "   attribute_tokens: [  4d8821270b4a47e3a8a300cbec48188e,   ]\n",
       "   translation:   Translation {\n",
       "     [373.245000, 1130.600000, 1.100000,     ]\n",
       "   }\n",
       "   rotation:   Rotation {\n",
       "     [0.983110, 0.000000, 0.000000, -0.183016,     ]\n",
       "   }\n",
       "   size: [0.621000, 0.669000, 1.642000,   ]\n",
       "   prev_token: 146b2111cc0c401ca09d96777758d81e\n",
       "   next_token: 807b3e029a6b4e428f6cc82fc26a35a7\n",
       " },\n",
       " Annotation {\n",
       "   token: 807b3e029a6b4e428f6cc82fc26a35a7\n",
       "   sample_token: 4246e57f018745c9b2bc68feb3d71b58\n",
       "   instance_token: 6dd2cbf4c24b4caeb625035869bca7b5\n",
       "   visibility_token: 2\n",
       "   attribute_tokens: [  4d8821270b4a47e3a8a300cbec48188e,   ]\n",
       "   translation:   Translation {\n",
       "     [373.245000, 1130.600000, 1.050000,     ]\n",
       "   }\n",
       "   rotation:   Rotation {\n",
       "     [0.983110, 0.000000, 0.000000, -0.183016,     ]\n",
       "   }\n",
       "   size: [0.621000, 0.669000, 1.642000,   ]\n",
       "   prev_token: a2f1d09320c3454ba3f2347c4b5903a5\n",
       "   next_token: f84a0a9fb64e4aab9ccd87e9fbf815e0\n",
       " },\n",
       " Annotation {\n",
       "   token: f84a0a9fb64e4aab9ccd87e9fbf815e0\n",
       "   sample_token: a7acb150914b40bdad9a2dc4e657cbf9\n",
       "   instance_token: 6dd2cbf4c24b4caeb625035869bca7b5\n",
       "   visibility_token: 1\n",
       "   attribute_tokens: [  4d8821270b4a47e3a8a300cbec48188e,   ]\n",
       "   translation:   Translation {\n",
       "     [373.245000, 1130.600000, 1.000000,     ]\n",
       "   }\n",
       "   rotation:   Rotation {\n",
       "     [0.983110, 0.000000, 0.000000, -0.183016,     ]\n",
       "   }\n",
       "   size: [0.621000, 0.669000, 1.642000,   ]\n",
       "   prev_token: 807b3e029a6b4e428f6cc82fc26a35a7\n",
       "   next_token: 7670ac8bc5044d5a9e11e205c839385d\n",
       " },\n",
       " Annotation {\n",
       "   token: 7670ac8bc5044d5a9e11e205c839385d\n",
       "   sample_token: 0cd661df01aa40c3bb3a773ba86f753a\n",
       "   instance_token: 6dd2cbf4c24b4caeb625035869bca7b5\n",
       "   visibility_token: 1\n",
       "   attribute_tokens: [  4d8821270b4a47e3a8a300cbec48188e,   ]\n",
       "   translation:   Translation {\n",
       "     [373.245000, 1130.600000, 0.950000,     ]\n",
       "   }\n",
       "   rotation:   Rotation {\n",
       "     [0.983110, 0.000000, 0.000000, -0.183016,     ]\n",
       "   }\n",
       "   size: [0.621000, 0.669000, 1.642000,   ]\n",
       "   prev_token: f84a0a9fb64e4aab9ccd87e9fbf815e0\n",
       "   next_token: 163d85048698495dbf55a35f613c5fb9\n",
       " },\n",
       " Annotation {\n",
       "   token: 163d85048698495dbf55a35f613c5fb9\n",
       "   sample_token: 378a3a3e9af346308ab9dff8ced46d9c\n",
       "   instance_token: 6dd2cbf4c24b4caeb625035869bca7b5\n",
       "   visibility_token: 1\n",
       "   attribute_tokens: [  4d8821270b4a47e3a8a300cbec48188e,   ]\n",
       "   translation:   Translation {\n",
       "     [373.245000, 1130.600000, 0.900000,     ]\n",
       "   }\n",
       "   rotation:   Rotation {\n",
       "     [0.983110, 0.000000, 0.000000, -0.183016,     ]\n",
       "   }\n",
       "   size: [0.621000, 0.669000, 1.642000,   ]\n",
       "   prev_token: 7670ac8bc5044d5a9e11e205c839385d\n",
       "   next_token: 3a930d1793434d9a8a87d6eba28ff70e\n",
       " },\n",
       " Annotation {\n",
       "   token: 3a930d1793434d9a8a87d6eba28ff70e\n",
       "   sample_token: eef55c3b48f34d949959b45130ee293a\n",
       "   instance_token: 6dd2cbf4c24b4caeb625035869bca7b5\n",
       "   visibility_token: 1\n",
       "   attribute_tokens: [  4d8821270b4a47e3a8a300cbec48188e,   ]\n",
       "   translation:   Translation {\n",
       "     [373.258000, 1130.608000, 0.928000,     ]\n",
       "   }\n",
       "   rotation:   Rotation {\n",
       "     [0.983110, 0.000000, 0.000000, -0.183016,     ]\n",
       "   }\n",
       "   size: [0.621000, 0.669000, 1.642000,   ]\n",
       "   prev_token: 163d85048698495dbf55a35f613c5fb9\n",
       "   next_token: f7e190375e1f4e569ba16fcdabf6e4b3\n",
       " },\n",
       " Annotation {\n",
       "   token: f7e190375e1f4e569ba16fcdabf6e4b3\n",
       "   sample_token: 5fda58ee3ae44ab9b4bbac7a2de66c27\n",
       "   instance_token: 6dd2cbf4c24b4caeb625035869bca7b5\n",
       "   visibility_token: 1\n",
       "   attribute_tokens: [  4d8821270b4a47e3a8a300cbec48188e,   ]\n",
       "   translation:   Translation {\n",
       "     [373.271000, 1130.617000, 0.956000,     ]\n",
       "   }\n",
       "   rotation:   Rotation {\n",
       "     [0.983110, 0.000000, 0.000000, -0.183016,     ]\n",
       "   }\n",
       "   size: [0.621000, 0.669000, 1.642000,   ]\n",
       "   prev_token: 3a930d1793434d9a8a87d6eba28ff70e\n",
       "   next_token: 6f371d3f0d7d494eaa6f81daa3df58c0\n",
       " },\n",
       " Annotation {\n",
       "   token: 6f371d3f0d7d494eaa6f81daa3df58c0\n",
       "   sample_token: 919e3c4cec934168a3152077a9adcbea\n",
       "   instance_token: 6dd2cbf4c24b4caeb625035869bca7b5\n",
       "   visibility_token: 1\n",
       "   attribute_tokens: [  4d8821270b4a47e3a8a300cbec48188e,   ]\n",
       "   translation:   Translation {\n",
       "     [373.285000, 1130.626000, 0.984000,     ]\n",
       "   }\n",
       "   rotation:   Rotation {\n",
       "     [0.983110, 0.000000, 0.000000, -0.183016,     ]\n",
       "   }\n",
       "   size: [0.621000, 0.669000, 1.642000,   ]\n",
       "   prev_token: f7e190375e1f4e569ba16fcdabf6e4b3\n",
       "   next_token: 90d94112b9ea4fb691e988b40af5b161\n",
       " },\n",
       " Annotation {\n",
       "   token: 90d94112b9ea4fb691e988b40af5b161\n",
       "   sample_token: b73152cab88f49d9ba195da81fde1809\n",
       "   instance_token: 6dd2cbf4c24b4caeb625035869bca7b5\n",
       "   visibility_token: 1\n",
       "   attribute_tokens: [  4d8821270b4a47e3a8a300cbec48188e,   ]\n",
       "   translation:   Translation {\n",
       "     [373.298000, 1130.635000, 1.012000,     ]\n",
       "   }\n",
       "   rotation:   Rotation {\n",
       "     [0.983110, 0.000000, 0.000000, -0.183016,     ]\n",
       "   }\n",
       "   size: [0.621000, 0.669000, 1.642000,   ]\n",
       "   prev_token: 6f371d3f0d7d494eaa6f81daa3df58c0\n",
       "   next_token: b964464ea45d4e9493f324ba8d2a82a3\n",
       " },\n",
       " Annotation {\n",
       "   token: b964464ea45d4e9493f324ba8d2a82a3\n",
       "   sample_token: 6aa6fa91e0d1492e812eb7e57c47df6e\n",
       "   instance_token: 6dd2cbf4c24b4caeb625035869bca7b5\n",
       "   visibility_token: 1\n",
       "   attribute_tokens: [  4d8821270b4a47e3a8a300cbec48188e,   ]\n",
       "   translation:   Translation {\n",
       "     [373.311000, 1130.643000, 1.039000,     ]\n",
       "   }\n",
       "   rotation:   Rotation {\n",
       "     [0.983110, 0.000000, 0.000000, -0.183016,     ]\n",
       "   }\n",
       "   size: [0.621000, 0.669000, 1.642000,   ]\n",
       "   prev_token: 90d94112b9ea4fb691e988b40af5b161\n",
       "   next_token: 794fcc425f074a1392206ed925fdbbd8\n",
       " },\n",
       " Annotation {\n",
       "   token: 794fcc425f074a1392206ed925fdbbd8\n",
       "   sample_token: aa581aac963a4fad848ac11fe66e8637\n",
       "   instance_token: 6dd2cbf4c24b4caeb625035869bca7b5\n",
       "   visibility_token: 1\n",
       "   attribute_tokens: [  4d8821270b4a47e3a8a300cbec48188e,   ]\n",
       "   translation:   Translation {\n",
       "     [373.324000, 1130.652000, 1.067000,     ]\n",
       "   }\n",
       "   rotation:   Rotation {\n",
       "     [0.983110, 0.000000, 0.000000, -0.183016,     ]\n",
       "   }\n",
       "   size: [0.621000, 0.669000, 1.642000,   ]\n",
       "   prev_token: b964464ea45d4e9493f324ba8d2a82a3\n",
       "   next_token: 3b24f083c0bf42d695a1040efdab7ffe\n",
       " },\n",
       " Annotation {\n",
       "   token: 3b24f083c0bf42d695a1040efdab7ffe\n",
       "   sample_token: 67e5f88901214f3aa03d68e028185e22\n",
       "   instance_token: 6dd2cbf4c24b4caeb625035869bca7b5\n",
       "   visibility_token: 1\n",
       "   attribute_tokens: [  4d8821270b4a47e3a8a300cbec48188e,   ]\n",
       "   translation:   Translation {\n",
       "     [373.337000, 1130.661000, 1.095000,     ]\n",
       "   }\n",
       "   rotation:   Rotation {\n",
       "     [0.983110, 0.000000, 0.000000, -0.183016,     ]\n",
       "   }\n",
       "   size: [0.621000, 0.669000, 1.642000,   ]\n",
       "   prev_token: 794fcc425f074a1392206ed925fdbbd8\n",
       "   next_token: 93d5b79041c64693a5b32f1103a39a06\n",
       " },\n",
       " Annotation {\n",
       "   token: 93d5b79041c64693a5b32f1103a39a06\n",
       "   sample_token: 29e056fc277543c9bc42310b122c640e\n",
       "   instance_token: 6dd2cbf4c24b4caeb625035869bca7b5\n",
       "   visibility_token: 1\n",
       "   attribute_tokens: [  4d8821270b4a47e3a8a300cbec48188e,   ]\n",
       "   translation:   Translation {\n",
       "     [373.350000, 1130.670000, 1.123000,     ]\n",
       "   }\n",
       "   rotation:   Rotation {\n",
       "     [0.983110, 0.000000, 0.000000, -0.183016,     ]\n",
       "   }\n",
       "   size: [0.621000, 0.669000, 1.642000,   ]\n",
       "   prev_token: 3b24f083c0bf42d695a1040efdab7ffe\n",
       "   next_token: 8bb63134d48840aaa2993f490855ff0d\n",
       " },\n",
       " Annotation {\n",
       "   token: 8bb63134d48840aaa2993f490855ff0d\n",
       "   sample_token: ed5fc18c31904f96a8f0dbb99ff069c0\n",
       "   instance_token: 6dd2cbf4c24b4caeb625035869bca7b5\n",
       "   visibility_token: 3\n",
       "   attribute_tokens: [  4d8821270b4a47e3a8a300cbec48188e,   ]\n",
       "   translation:   Translation {\n",
       "     [373.363000, 1130.678000, 1.150000,     ]\n",
       "   }\n",
       "   rotation:   Rotation {\n",
       "     [0.983110, 0.000000, 0.000000, -0.183016,     ]\n",
       "   }\n",
       "   size: [0.621000, 0.669000, 1.642000,   ]\n",
       "   prev_token: 93d5b79041c64693a5b32f1103a39a06\n",
       "   next_token: \n",
       " }]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anns = one_instance.annotations\n",
    "anns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returns a list of all sample_annotation records with the `'instance_token'` == `one_instance['token']`. Let's store these in a set for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'05e0ad1194804f548be544f2267c7e74',\n",
       " '060be69422ee4b2a8b239b463b995e92',\n",
       " '146b2111cc0c401ca09d96777758d81e',\n",
       " '163d85048698495dbf55a35f613c5fb9',\n",
       " '17a6843fefcd4b2b811eddbb1ccd708d',\n",
       " '1de9ad564050444486eb587360cf135f',\n",
       " '1e8e35d365a441a18dd5503a0ee1c208',\n",
       " '23f10d5f0d254068941be8797493c7eb',\n",
       " '2b5948828cdb49e3be6be1320381bbbf',\n",
       " '3a930d1793434d9a8a87d6eba28ff70e',\n",
       " '3b24f083c0bf42d695a1040efdab7ffe',\n",
       " '4e41d9560dbf46cab1568b8ef6a282f3',\n",
       " '6f371d3f0d7d494eaa6f81daa3df58c0',\n",
       " '70aecbe9b64f4722ab3c230391a3beb8',\n",
       " '74f550e3257c4f52af1102c0d49d37b8',\n",
       " '7670ac8bc5044d5a9e11e205c839385d',\n",
       " '794fcc425f074a1392206ed925fdbbd8',\n",
       " '7987617983634b119e383d8a29607fd7',\n",
       " '7fa3a688931b4500b7ce29d187d3b975',\n",
       " '807b3e029a6b4e428f6cc82fc26a35a7',\n",
       " '8bb63134d48840aaa2993f490855ff0d',\n",
       " '90d94112b9ea4fb691e988b40af5b161',\n",
       " '913072e56d6c4025b9b47ba085dd6d7c',\n",
       " '93d5b79041c64693a5b32f1103a39a06',\n",
       " '9acb7dfed3454f72b2874dda3bdacc48',\n",
       " 'a1721876c0944cdd92ebc3c75d55d693',\n",
       " 'a2b20cdbf1ed4018ac795b8845d5deaa',\n",
       " 'a2f1d09320c3454ba3f2347c4b5903a5',\n",
       " 'a72013a0352a496c9a01832f5666ae31',\n",
       " 'b38209aa7b0c49a5b910e7b774b07bd5',\n",
       " 'b8f593154b8144f58e1e53d3c91ab567',\n",
       " 'b964464ea45d4e9493f324ba8d2a82a3',\n",
       " 'd15155fecf2f440c97bb0781777e18d4',\n",
       " 'e5fe9ea066254609b48eb073e81ef209',\n",
       " 'ed72884bda8a4332bbcb80c285a97929',\n",
       " 'ef63a697930c4b20a6b9791f423351da',\n",
       " 'f503fa3d050f43cca4af2241b674929a',\n",
       " 'f7e190375e1f4e569ba16fcdabf6e4b3',\n",
       " 'f84a0a9fb64e4aab9ccd87e9fbf815e0'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_tokens_field2token = set([a.token for a in anns])\n",
    "ann_tokens_field2token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `nusc.field2token()` method is generic and can be used in any similar situation.\n",
    "\n",
    "2. For certain situation, we provide some reverse indices in the tables themselves. This is one such example. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The instance record has a field `first_annotation_token` which points to the first annotation in time of this instance. \n",
    "Recovering this record is easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Annotation {\n",
       "  token: ef63a697930c4b20a6b9791f423351da\n",
       "  sample_token: ca9a282c9e77460f8360f564131a8af5\n",
       "  instance_token: 6dd2cbf4c24b4caeb625035869bca7b5\n",
       "  visibility_token: 1\n",
       "  attribute_tokens: [  4d8821270b4a47e3a8a300cbec48188e,   ]\n",
       "  translation:   Translation {\n",
       "    [373.256000, 1130.419000, 0.800000,     ]\n",
       "  }\n",
       "  rotation:   Rotation {\n",
       "    [0.983110, 0.000000, 0.000000, -0.183016,     ]\n",
       "  }\n",
       "  size: [0.621000, 0.669000, 1.642000,   ]\n",
       "  prev_token: \n",
       "  next_token: 7987617983634b119e383d8a29607fd7\n",
       "}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_record = one_instance.annotations[0]\n",
    "ann_record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can traverse all annotations of this instance using the \"next\" field. Let's try it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_tokens_traverse = set()\n",
    "ann_tokens_traverse.add(ann_record.token)\n",
    "while not ann_record.next_token == \"\":\n",
    "    ann_record = nusc.annotation(ann_record.next_token)\n",
    "    ann_tokens_traverse.add(ann_record.token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's assert that we recovered the same ann_records as we did using nusc.field2token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "39\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(len(ann_tokens_field2token))\n",
    "print(len(ann_tokens_traverse))\n",
    "print(ann_tokens_traverse == ann_tokens_field2token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reverse indexing and short-cuts\n",
    "\n",
    "The nuScenes tables are normalized, meaning that each piece of information is only given once.\n",
    "For example, there is one `map` record for each `log` record. Looking at the schema you will notice that the `map` table has a `log_token` field, but that the `log` table does not have a corresponding `map_token` field. But there are plenty of situations where you have a `log`, and want to find the corresponding `map`! So what to do? You can always use the `nusc.field2token()` method, but that is slow and inconvenient. We therefore add reverse mappings for some common situations including this one.\n",
    "\n",
    "Further, there are situations where one needs to go through several tables to get a certain piece of information. \n",
    "Consider, for example, the category name (e.g. `human.pedestrian`) of a `sample_annotation`. The `sample_annotation` table doesn't hold this information since the category is an instance level constant. Instead the `sample_annotation` table points to a record in the `instance` table. This, in turn, points to a record in the `category` table, where finally the `name` fields stores the required information.\n",
    "\n",
    "Since it is quite common to want to know the category name of an annotation, we add a `category_name` field to the `sample_annotation` table during initialization of the NuScenes class.\n",
    "\n",
    "In this section, we list the short-cuts and reverse indices that are added to the `NuScenes` class during initialization. These are all created in the `NuScenes.__make_reverse_index__()` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reverse indices\n",
    "We add two reverse indices by default.\n",
    "* A `map_token` field is added to the `log` records.\n",
    "* The `sample` records have shortcuts to all `sample_annotations` for that record as well as `sample_data` key-frames. Confer `nusc.list_sample()` method in the previous section for more details on this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualizations\n",
    "\n",
    "We provide list and rendering methods. These are meant both as convenience methods during development, and as tutorials for building your own visualization methods. They are implemented in the NuScenesExplorer class, with shortcuts through the NuScenes class itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List methods\n",
    "There are three list methods available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `list_categories()` lists all categories, counts and statistics of width/length/height in meters and aspect ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Category {\n",
       "   token: 1fa93b757fc74fb197cdd60001ad8abf\n",
       "   name: human.pedestrian.adult\n",
       "   description: Adult subcategory.\n",
       " },\n",
       " Category {\n",
       "   token: b1c6de4c57f14a5383d9f963fbdcb5cb\n",
       "   name: human.pedestrian.child\n",
       "   description: Child subcategory.\n",
       " },\n",
       " Category {\n",
       "   token: b2d7c6c701254928a9e4d6aac9446d79\n",
       "   name: human.pedestrian.wheelchair\n",
       "   description: Wheelchairs. If a person is in the wheelchair, include in the annotation.\n",
       " },\n",
       " Category {\n",
       "   token: 6a5888777ca14867a8aee3fe539b56c4\n",
       "   name: human.pedestrian.stroller\n",
       "   description: Strollers. If a person is in the stroller, include in the annotation.\n",
       " },\n",
       " Category {\n",
       "   token: 403fede16c88426885dd73366f16c34a\n",
       "   name: human.pedestrian.personal_mobility\n",
       "   description: A small electric or self-propelled vehicle, e.g. skateboard, segway, or scooters, on which the person typically travels in a upright position. Driver and (if applicable) rider should be included in the bounding box along with the vehicle.\n",
       " },\n",
       " Category {\n",
       "   token: bb867e2064014279863c71a29b1eb381\n",
       "   name: human.pedestrian.police_officer\n",
       "   description: Police officer.\n",
       " },\n",
       " Category {\n",
       "   token: 909f1237d34a49d6bdd27c2fe4581d79\n",
       "   name: human.pedestrian.construction_worker\n",
       "   description: Construction worker\n",
       " },\n",
       " Category {\n",
       "   token: 63a94dfa99bb47529567cd90d3b58384\n",
       "   name: animal\n",
       "   description: All animals, e.g. cats, rats, dogs, deer, birds.\n",
       " },\n",
       " Category {\n",
       "   token: fd69059b62a3469fbaef25340c0eab7f\n",
       "   name: vehicle.car\n",
       "   description: Vehicle designed primarily for personal use, e.g. sedans, hatch-backs, wagons, vans, mini-vans, SUVs and jeeps. If the vehicle is designed to carry more than 10 people use vehicle.bus. If it is primarily designed to haul cargo use vehicle.truck. \n",
       " },\n",
       " Category {\n",
       "   token: dfd26f200ade4d24b540184e16050022\n",
       "   name: vehicle.motorcycle\n",
       "   description: Gasoline or electric powered 2-wheeled vehicle designed to move rapidly (at the speed of standard cars) on the road surface. This category includes all motorcycles, vespas and scooters.\n",
       " },\n",
       " Category {\n",
       "   token: fc95c87b806f48f8a1faea2dcc2222a4\n",
       "   name: vehicle.bicycle\n",
       "   description: Human or electric powered 2-wheeled vehicle designed to travel at lower speeds either on road surface, sidewalks or bike paths.\n",
       " },\n",
       " Category {\n",
       "   token: 003edbfb9ca849ee8a7496e9af3025d4\n",
       "   name: vehicle.bus.bendy\n",
       "   description: Bendy bus subcategory. Annotate each section of the bendy bus individually.\n",
       " },\n",
       " Category {\n",
       "   token: fedb11688db84088883945752e480c2c\n",
       "   name: vehicle.bus.rigid\n",
       "   description: Rigid bus subcategory.\n",
       " },\n",
       " Category {\n",
       "   token: 6021b5187b924d64be64a702e5570edf\n",
       "   name: vehicle.truck\n",
       "   description: Vehicles primarily designed to haul cargo including pick-ups, lorrys, trucks and semi-tractors. Trailers hauled after a semi-tractor should be labeled as vehicle.trailer\n",
       " },\n",
       " Category {\n",
       "   token: 5b3cd6f2bca64b83aa3d0008df87d0e4\n",
       "   name: vehicle.construction\n",
       "   description: Vehicles primarily designed for construction. Typically very slow moving or stationary. Cranes and extremities of construction vehicles are only included in annotations if they interfere with traffic. Trucks used to haul rocks or building materials are considered vehicle.truck rather than construction vehicles.\n",
       " },\n",
       " Category {\n",
       "   token: 732cce86872640628788ff1bb81006d4\n",
       "   name: vehicle.emergency.ambulance\n",
       "   description: All types of ambulances.\n",
       " },\n",
       " Category {\n",
       "   token: 7b2ff083a64e4d53809ae5d9be563504\n",
       "   name: vehicle.emergency.police\n",
       "   description: All types of police vehicles including police bicycles and motorcycles.\n",
       " },\n",
       " Category {\n",
       "   token: 90d0f6f8e7c749149b1b6c3a029841a8\n",
       "   name: vehicle.trailer\n",
       "   description: Any vehicle trailer, both for trucks, cars and bikes.\n",
       " },\n",
       " Category {\n",
       "   token: 653f7efbb9514ce7b81d44070d6208c1\n",
       "   name: movable_object.barrier\n",
       "   description: Temporary road barrier placed in the scene in order to redirect traffic. Commonly used at construction sites. This includes concrete barrier, metal barrier and water barrier. No fences.\n",
       " },\n",
       " Category {\n",
       "   token: 85abebdccd4d46c7be428af5a6173947\n",
       "   name: movable_object.trafficcone\n",
       "   description: All types of traffic cone.\n",
       " },\n",
       " Category {\n",
       "   token: d772e4bae20f493f98e15a76518b31d7\n",
       "   name: movable_object.pushable_pullable\n",
       "   description: Objects that a pedestrian may push or pull. For example dolleys, wheel barrows, garbage-bins, or shopping carts.\n",
       " },\n",
       " Category {\n",
       "   token: 063c5e7f638343d3a7230bc3641caf97\n",
       "   name: movable_object.debris\n",
       "   description: Movable object that is left on the driveable surface that is too large to be driven over safely, e.g tree branch, full trash bag etc.\n",
       " },\n",
       " Category {\n",
       "   token: 0a30519ee16a4619b4f4acfe2d78fb55\n",
       "   name: static_object.bicycle_rack\n",
       "   description: Area or device intended to park or secure the bicycles in a row. It includes all the bikes parked in it and any empty slots that are intended for parking bikes.\n",
       " }]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nusc.categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. `list_attributes()` lists all attributes and counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Attribute {\n",
       "   token: cb5118da1ab342aa947717dc53544259\n",
       "   name: vehicle.moving\n",
       "   description: Vehicle is moving.\n",
       " },\n",
       " Attribute {\n",
       "   token: c3246a1e22a14fcb878aa61e69ae3329\n",
       "   name: vehicle.stopped\n",
       "   description: Vehicle, with a driver/rider in/on it, is currently stationary but has an intent to move.\n",
       " },\n",
       " Attribute {\n",
       "   token: 58aa28b1c2a54dc88e169808c07331e3\n",
       "   name: vehicle.parked\n",
       "   description: Vehicle is stationary (usually for longer duration) with no immediate intent to move.\n",
       " },\n",
       " Attribute {\n",
       "   token: a14936d865eb4216b396adae8cb3939c\n",
       "   name: cycle.with_rider\n",
       "   description: There is a rider on the bicycle or motorcycle.\n",
       " },\n",
       " Attribute {\n",
       "   token: 5a655f9751944309a277276b8f473452\n",
       "   name: cycle.without_rider\n",
       "   description: There is NO rider on the bicycle or motorcycle.\n",
       " },\n",
       " Attribute {\n",
       "   token: 03aa62109bf043afafdea7d875dd4f43\n",
       "   name: pedestrian.sitting_lying_down\n",
       "   description: The human is sitting or lying down.\n",
       " },\n",
       " Attribute {\n",
       "   token: 4d8821270b4a47e3a8a300cbec48188e\n",
       "   name: pedestrian.standing\n",
       "   description: The human is standing.\n",
       " },\n",
       " Attribute {\n",
       "   token: ab83627ff28b465b85c427162dec722f\n",
       "   name: pedestrian.moving\n",
       "   description: The human is moving.\n",
       " }]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nusc.attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. `list_scenes()` lists all scenes in the loaded DB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Scene {\n",
       "   token: cc8c0bf57f984915a77078b10eb33198\n",
       "   nbr_samples: 39\n",
       "   first_sample_token: ca9a282c9e77460f8360f564131a8af5\n",
       "   last_sample_token: ed5fc18c31904f96a8f0dbb99ff069c0\n",
       "   name: scene-0061\n",
       " },\n",
       " Scene {\n",
       "   token: fcbccedd61424f1b85dcbf8f897f9754\n",
       "   nbr_samples: 40\n",
       "   first_sample_token: 3e8750f331d7499e9b5123e9eb70f2e2\n",
       "   last_sample_token: 281b92269fd648d4b52d06ac06ca6d65\n",
       "   name: scene-0103\n",
       " },\n",
       " Scene {\n",
       "   token: 6f83169d067343658251f72e1dd17dbc\n",
       "   nbr_samples: 41\n",
       "   first_sample_token: 8687ba92abd3406aa797115b874ebeba\n",
       "   last_sample_token: dcbe451d383e450786aaad04ab9d3790\n",
       "   name: scene-0553\n",
       " },\n",
       " Scene {\n",
       "   token: bebf5f5b2a674631ab5c88fd1aa9e87a\n",
       "   nbr_samples: 41\n",
       "   first_sample_token: 5991fad3280c4f84b331536c32001a04\n",
       "   last_sample_token: 35833ae5808e4ef186d1fdebac3d9cf6\n",
       "   name: scene-0655\n",
       " },\n",
       " Scene {\n",
       "   token: 2fc3753772e241f2ab2cd16a784cc680\n",
       "   nbr_samples: 41\n",
       "   first_sample_token: cd9964f8c3d34383b16e9c2997de1ed0\n",
       "   last_sample_token: 8fe9664cec514a58b1184c4fcefda6b5\n",
       "   name: scene-0757\n",
       " },\n",
       " Scene {\n",
       "   token: c5224b9b454b4ded9b5d2d2634bbda8a\n",
       "   nbr_samples: 40\n",
       "   first_sample_token: c1676a2feac74eee8aa38ca3901787d6\n",
       "   last_sample_token: 63c24b51feb94f14bec29022dae4975d\n",
       "   name: scene-0796\n",
       " },\n",
       " Scene {\n",
       "   token: 325cef682f064c55a255f2625c533b75\n",
       "   nbr_samples: 41\n",
       "   first_sample_token: b5989651183643369174912bc5641d3b\n",
       "   last_sample_token: b4ff30109dd14c89b24789dc5713cf8c\n",
       "   name: scene-0916\n",
       " },\n",
       " Scene {\n",
       "   token: d25718445d89453381c659b9c8734939\n",
       "   nbr_samples: 41\n",
       "   first_sample_token: 5998b71b64c146769bde1d5430741381\n",
       "   last_sample_token: ee9b3f38dadd40588f43ba590c4751b9\n",
       "   name: scene-1077\n",
       " },\n",
       " Scene {\n",
       "   token: de7d80a1f5fb4c3e82ce8a4f213b450a\n",
       "   nbr_samples: 40\n",
       "   first_sample_token: e6b0b282aa174a978272dc2d0a89d560\n",
       "   last_sample_token: 4e1d1031fe9f45f981a2f598365fc645\n",
       "   name: scene-1094\n",
       " },\n",
       " Scene {\n",
       "   token: e233467e827140efa4b42d2b4c435855\n",
       "   nbr_samples: 40\n",
       "   first_sample_token: a480496a5988410fbe3d8ed6c84da996\n",
       "   last_sample_token: abf3d91d3c28407e80e3334fe89c03cb\n",
       "   name: scene-1100\n",
       " }]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nusc.scenes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
